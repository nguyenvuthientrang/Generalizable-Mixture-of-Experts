WARNING:root:[31mYou are loading a legacy format of checkpoint with at least one Tutel MoE layer inside, which wouldn't support new Tutel feature allowing the number of experts per checkpoint file to mutate.[0m
WARNING:root:[31m  The next time you overwrite it with new checkpoint, the recording format will be updated automatically.[0m
WARNING:root:[31m  However, the new format won't be compatible with early Tutel versions, unless you force loading it with `model.load_state_dict(.., strict=False)`.[0m
WARNING:root:[31mYou are loading a legacy format of checkpoint with at least one Tutel MoE layer inside, which wouldn't support new Tutel feature allowing the number of experts per checkpoint file to mutate.[0m
WARNING:root:[31m  The next time you overwrite it with new checkpoint, the recording format will be updated automatically.[0m
WARNING:root:[31m  However, the new format won't be compatible with early Tutel versions, unless you force loading it with `model.load_state_dict(.., strict=False)`.[0m
Traceback (most recent call last):
  File "/lustre/scratch/client/vinai/users/trangnvt/envs/moe/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/lustre/scratch/client/vinai/users/trangnvt/envs/moe/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/domainbed/scripts/train.py", line 243, in <module>
    step_vals = algorithm.update(minibatches_device)
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/domainbed/algorithms.py", line 202, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/domainbed/algorithms.py", line 223, in predict
    prediction = self.model(x)
  File "/lustre/scratch/client/vinai/users/trangnvt/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/lustre/scratch/client/vinai/users/trangnvt/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/domainbed/vision_transformer.py", line 419, in forward
    x = self.forward_features(x, domain_index)
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/domainbed/vision_transformer.py", line 411, in forward_features
    x = blk(x, domain_index)
  File "/lustre/scratch/client/vinai/users/trangnvt/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/lustre/scratch/client/vinai/users/trangnvt/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/domainbed/vision_transformer.py", line 274, in forward
    x = x + self.drop_path(self.mlp(self.norm2(x)))
  File "/lustre/scratch/client/vinai/users/trangnvt/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/lustre/scratch/client/vinai/users/trangnvt/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/tutel/tutel/impls/moe_layer.py", line 301, in forward
    logits_dtype, (crit, l_aux) = routing()
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/tutel/tutel/impls/moe_layer.py", line 287, in routing
    return logits.dtype, extract_critical(scores,
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/tutel/tutel/impls/fast_dispatch.py", line 150, in extract_critical
    l_loss = loss_fn(scores, topk_indices) if loss_fn is not None else None
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/tutel/tutel/impls/moe_layer.py", line 281, in <lambda>
    _loss_fn = lambda gates, topk_ids: losses.load_importance_loss(
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/tutel/tutel/impls/losses.py", line 42, in load_importance_loss
    l_load = load_loss(scores_wo_noise, topk_logits, num_global_experts, gate_noise)
  File "/lustre/scratch/client/vinai/users/trangnvt2/Generalizable-Mixture-of-Experts/tutel/tutel/impls/losses.py", line 23, in load_loss
    assert gate_noise > 0, "`gate_noise` must be > 0 for normalization in load_importance_loss()."
AssertionError: `gate_noise` must be > 0 for normalization in load_importance_loss().
